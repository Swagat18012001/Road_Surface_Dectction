{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4HZs4PGM-3p"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixC6AOjwNMA6",
        "outputId": "c88b8852-af4c-459f-eecd-0b093bbc8a3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = Path('gdrive/My Drive/Dataset/Image/')"
      ],
      "metadata": {
        "id": "030l2GELNMDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths to the dataset\n",
        "dry_path = path/'dry'\n",
        "snowy_path = path/'snowy'\n",
        "wet_path = path/'wet'"
      ],
      "metadata": {
        "id": "aaLQuwuYNMGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize image size and batch size\n",
        "image_size = 128\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "Fincja0MNNA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the images\n",
        "def load_images(path):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for subdir in ['dry', 'snowy', 'wet']:\n",
        "        subpath = path / subdir\n",
        "        for filename in os.listdir(subpath):\n",
        "            img = cv.imread(os.path.join(subpath, filename))\n",
        "            img = cv.resize(img, (image_size, image_size))\n",
        "            img = img.astype('float32') / 255.0\n",
        "            images.append(img)\n",
        "            labels.append(subdir)\n",
        "    return np.array(images), np.array(labels)"
      ],
      "metadata": {
        "id": "a85YQVFY2DeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "X, y = load_images(path)"
      ],
      "metadata": {
        "id": "7fKwfjLv2FuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to integers if they are not already one-hot encoded\n",
        "if y.shape[1] != 3:  # Check if y is not already one-hot encoded\n",
        "    label_map = {'dry': 0, 'snowy': 1, 'wet': 2}\n",
        "    y_int = np.array([label_map[label] for label in y])  # Convert labels to integers\n",
        "    y_encoded = tf.keras.utils.to_categorical(y_int)  # One-hot encode the labels\n",
        "else:\n",
        "    y_encoded = y  # y is already one-hot encoded, so no conversion is needed\n",
        "\n",
        "# Split the dataset into training, validation, and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "z_c2qqt2-z6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an ImageDataGenerator for data augmentation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                    rotation_range=20,\n",
        "                                    width_shift_range=0.2,\n",
        "                                    height_shift_range=0.2,\n",
        "                                    horizontal_flip=True,\n",
        "                                    fill_mode='nearest')\n",
        "\n",
        "# Prepare the training dataset\n",
        "train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "TlbMsnCQNM-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(image_size, image_size, 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(3, activation='softmax')  # 3 output classes: dry, snowy, wet\n",
        "])"
      ],
      "metadata": {
        "id": "RL4NmSQ6NM5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "-1UATWIMNM3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(train_generator, epochs=10, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Go8mmP3zNM0U",
        "outputId": "3c7b2abd-063c-4471-8cad-434cbbf23fd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "25/25 [==============================] - 40s 1s/step - loss: 0.9345 - accuracy: 0.7599 - val_loss: 13.4076 - val_accuracy: 0.7203\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 30s 1s/step - loss: 0.6532 - accuracy: 0.7867 - val_loss: 13.2028 - val_accuracy: 0.7203\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 33s 1s/step - loss: 0.6403 - accuracy: 0.7867 - val_loss: 14.2199 - val_accuracy: 0.7203\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 30s 1s/step - loss: 0.6414 - accuracy: 0.7867 - val_loss: 13.5961 - val_accuracy: 0.7203\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 31s 1s/step - loss: 0.6407 - accuracy: 0.7867 - val_loss: 13.7847 - val_accuracy: 0.7203\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 30s 1s/step - loss: 0.6441 - accuracy: 0.7867 - val_loss: 14.4952 - val_accuracy: 0.7203\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 32s 1s/step - loss: 0.6415 - accuracy: 0.7867 - val_loss: 13.2717 - val_accuracy: 0.7203\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 33s 1s/step - loss: 0.6385 - accuracy: 0.7867 - val_loss: 13.9139 - val_accuracy: 0.7203\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 31s 1s/step - loss: 0.6405 - accuracy: 0.7867 - val_loss: 13.8137 - val_accuracy: 0.7203\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 33s 1s/step - loss: 0.6425 - accuracy: 0.7867 - val_loss: 14.8027 - val_accuracy: 0.7203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "model.save('road_surface_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w54ZhYtGNMxc",
        "outputId": "ef38465b-4b77-4978-e161-c44b0a87b385"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model for inference\n",
        "model = tf.keras.models.load_model('road_surface_model.h5')"
      ],
      "metadata": {
        "id": "dn0MLXaPNMvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_road_surface(image_path):\n",
        "    img = cv.imread(str(image_path))\n",
        "    img = cv.resize(img, (image_size, image_size))\n",
        "    img = img.astype('float32') / 255.0\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    prediction = model.predict(img)\n",
        "    return np.argmax(prediction)\n",
        "\n",
        "# Example usage:\n",
        "image_path = path/'wet/wet00009.jpg'\n",
        "road_condition = classify_road_surface(image_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_KVzaKSNMss",
        "outputId": "982b4335-163b-4dad-8873-ba62c34206c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 31ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define class labels\n",
        "class_labels = {0: 'Dry', 1: 'Snowy', 2: 'Wet'}\n",
        "\n",
        "# Print the predicted road condition\n",
        "print(f\"The predicted road condition is: {class_labels[road_condition]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf1BlB7aNMqG",
        "outputId": "dc2adfe6-c12e-4cf0-cdbf-b2b112fa0800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted road condition is: Dry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_AIyCifFNMnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "joK1BHRqNMkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "InAZxLCaU3HP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TZAbkxpyU3Ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QuWincyJU3B9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g4gAQtxPU2_k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}